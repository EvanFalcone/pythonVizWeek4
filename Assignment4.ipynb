{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "This assignment requires that you to find **at least** two datasets on the web which are related, and that you visualize these datasets to answer a question with the broad topic of **sports or athletics** (see below) for the region of **Rosmalen, North Brabant, Netherlands**, or **Netherlands** more broadly.\n",
    "\n",
    "You can merge these datasets with data from different regions if you like! For instance, you might want to compare **Rosmalen, North Brabant, Netherlands** to Ann Arbor, USA. In that case at least one source file must be about **Rosmalen, North Brabant, Netherlands**.\n",
    "\n",
    "You are welcome to choose datasets at your discretion, but keep in mind **they will be shared with your peers**, so choose appropriate datasets. Sensitive, confidential, illicit, and proprietary materials are not good choices for datasets for this assignment. You are welcome to upload datasets of your own as well, and link to them using a third party repository such as github, bitbucket, pastebin, etc. Please be aware of the Coursera terms of service with respect to intellectual property.\n",
    "\n",
    "Also, you are welcome to preserve data in its original language, but for the purposes of grading you should provide english translations. You are welcome to provide multiple visuals in different languages if you would like!\n",
    "\n",
    "As this assignment is for the whole course, you must incorporate principles discussed in the first week, such as having as high data-ink ratio (Tufte) and aligning with Cairo’s principles of truth, beauty, function, and insight.\n",
    "\n",
    "Here are the assignment instructions:\n",
    "\n",
    " * State the region and the domain category that your data sets are about (e.g., **Rosmalen, North Brabant, Netherlands** and **sports or athletics**).\n",
    " * You must state a question about the domain category and region that you identified as being interesting.\n",
    " * You must provide at least two links to available datasets. These could be links to files such as CSV or Excel files, or links to websites which might have data in tabular form, such as Wikipedia pages.\n",
    " * You must upload an image which addresses the research question you stated. In addition to addressing the question, this visual should follow Cairo's principles of truthfulness, functionality, beauty, and insightfulness.\n",
    " * You must contribute a short (1-2 paragraph) written justification of how your visualization addresses your stated research question.\n",
    "\n",
    "What do we mean by **sports or athletics**?  For this category we are interested in sporting events or athletics broadly, please feel free to creatively interpret the category when building your research question!\n",
    "\n",
    "## Tips\n",
    "* Wikipedia is an excellent source of data, and I strongly encourage you to explore it for new data sources.\n",
    "* Many governments run open data initiatives at the city, region, and country levels, and these are wonderful resources for localized data sources.\n",
    "* Several international agencies, such as the [United Nations](http://data.un.org/), the [World Bank](http://data.worldbank.org/), the [Global Open Data Index](http://index.okfn.org/place/) are other great places to look for data.\n",
    "* This assignment requires you to convert and clean datafiles. Check out the discussion forums for tips on how to do this from various sources, and share your successes with your fellow students!\n",
    "\n",
    "## Example\n",
    "Looking for an example? Here's what our course assistant put together for the **Ann Arbor, MI, USA** area using **sports and athletics** as the topic. [Example Solution File](./readonly/Assignment4_example.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import gridspec\n",
    "import json as js \n",
    "import seaborn as sns\n",
    "import sys\n",
    "path = 'https://raw.githubusercontent.com/EvanFalcone/pythonVizWeek4/master/'\n",
    "\n",
    "################################################################################\n",
    "# Load dataset\n",
    "################################################################################\n",
    "load_pickle = 1\n",
    "\n",
    "# Load population and Gross domestic product from an internet source\n",
    "# When it is loaded once you can choose to load it from a pickle (temp file of pandas)\n",
    "if load_pickle==0:\n",
    "    df_pop = pd.read_pickle('dutch_population.pkl') #to load dutch_population.pkl back to the dataframe df\n",
    "    df_gdp = pd.read_pickle('dutch_gdp.pkl') #to load dutch_population.pkl back to the dataframe df\n",
    "else:   \n",
    "    #numbers about population in the Netherlands\n",
    "    json_pop = pd.read_json(\"https://opendata.cbs.nl/ODataApi/OData/37296ned/TypedDataSet\", orient=\"columns\")\n",
    "    df_pop = pd.read_json((json_pop['value']).to_json(), orient='index')\n",
    "    df_pop.to_pickle('dutch_population.pkl')    #to save the dataframe, df dutch_population.pkl\n",
    "    #numbers about gross domestic product in the Netherlands\n",
    "    json_gdp = pd.read_json(\"https://opendata.cbs.nl/ODataApi/OData/81170ned/TypedDataSet\", orient=\"columns\")\n",
    "    df_gdp = pd.read_json((json_gdp['value']).to_json(), orient='index')\n",
    "    df_gdp.to_pickle('dutch_gdp.pkl')\n",
    "\n",
    "    \n",
    "# Clean and prepare GDP dataset\n",
    "df_gdp = df_gdp[['Perioden', 'BrutoNationaalInkomen_77',\n",
    "                 'BrutoBinnenlandsProduct_2', 'BrutoBeschikbaarNationaalInkomen_81', 'ProductgebondenBelastingen_202' ]]\n",
    "df_gdp = df_gdp[df_gdp['Perioden'].str.contains(\"JJ\")]    \n",
    "df_gdp['Perioden'] = df_gdp['Perioden'].astype(str).str[:-4].astype(np.int64)\n",
    "df_gdp = df_gdp.sort_values(by=['Perioden'])\n",
    "\n",
    "df_gdp_grouped = df_gdp.groupby(['Perioden', 'BrutoNationaalInkomen_77',\n",
    "                                 'BrutoBinnenlandsProduct_2',  \n",
    "                                 'BrutoBeschikbaarNationaalInkomen_81'])['ProductgebondenBelastingen_202']\n",
    "\n",
    "df_gdp = pd.DataFrame(df_gdp_grouped.size().reset_index(name = \"Group_Count\"))\n",
    "df_gdp = df_gdp.rename(columns={'Perioden': 'Year', \n",
    "                                'BrutoBinnenlandsProduct_2': 'GDP',\n",
    "                                'BrutoNationaalInkomen_77': 'GrossNationalIncome',\n",
    "                                'BrutoBeschikbaarNationaalInkomen_81': 'GrossAvailableIncome',\n",
    "                                'Group_count': 'Group_count'})\n",
    "df_gdp.drop(df_gdp.columns[[-1]], axis=1, inplace=True)\n",
    "\n",
    "# Clean and prepare population dataset \n",
    "df_pop = df_pop[['Perioden', 'TotaleBevolking_1',                 \n",
    "                 'JongerDan20Jaar_10','k_20Tot40Jaar_11' ,\n",
    "                 'k_40Tot65Jaar_12' , 'k_65Tot80Jaar_13',\n",
    "                 'k_80JaarOfOuder_14' ]]\n",
    "df_pop['Perioden'] = df_pop['Perioden'].astype(str).str[:-4].astype(np.int64)\n",
    "df_pop['65AndOlder'] = df_pop['k_65Tot80Jaar_13'] + df_pop['k_80JaarOfOuder_14']\n",
    "df_pop['20-65 yr'] = df_pop['k_20Tot40Jaar_11'] + df_pop['k_40Tot65Jaar_12']\n",
    "df_pop = df_pop.rename(columns={'Perioden': 'Year', \n",
    "                                'TotaleBevolking_1': 'TotalPopulation',\n",
    "                                'JongerDan20Jaar_10' : '< 20 yr',\n",
    "                                'k_20Tot40Jaar_11' : '20-40 yr',\n",
    "                                'k_40Tot65Jaar_12': '40-65 yr',\n",
    "                                'k_65Tot80Jaar_13': '65To80Years',\n",
    "                                'k_80JaarOfOuder_14': '80AndOlder',\n",
    "                                 '65AndOlder': 'Seniors > 65 yr'})\n",
    "df_pop.drop(df_pop.columns[[-3, -3]], axis=1, inplace=True)\n",
    "pie_labels = ['Year', '< 20 yr', '20-65 yr', 'Seniors > 65 yr']\n",
    "df_pie_chart = df_pop[pie_labels].copy()\n",
    "df_pie_chart = df_pie_chart.set_index('Year')\n",
    "\n",
    "# Dataset about labor force in the netherlands (X1000)\n",
    "df_labor = pd.read_csv('labor_force.csv', delimiter=\";\")\n",
    "df_labor =df_labor.iloc[[0,1,2, -2],7:] #keep lines 0, 1, 2 and last 2, starting from col 7\n",
    "cols = [c for c in df_labor.columns if c.lower()[8:] != 'kwartaal'] #remove columns with in header\n",
    "df_labor = df_labor[cols] .T\n",
    "\n",
    "df_labor = df_labor.rename(columns={0: 'Year',\n",
    "                                1: 'LaborForce',\n",
    "                                2: 'Employed',\n",
    "                                19: 'Unemployed'})\n",
    "df_labor['Year'] = df_labor['Year'].astype('int')\n",
    "\n",
    "# Dataset about pension costs government\n",
    "df_pension = pd.read_csv('pension_exp_gov.csv', delimiter=\";\")\n",
    "df_pension =df_pension.iloc[:,4:] #keep line 1, starting from col 7\n",
    "df_pension.columns = df_pension.columns.str.replace(\"*\", \"\") #if column header contains * replace with empty str\n",
    "df_pension = df_pension.T# transform table\n",
    "df_pension = df_pension.rename(columns={0: 'Year', 1: 'PensionCosts'}) # rename columns\n",
    "df_pension =df_pension.iloc[:-2,:] #remove last 2 lines\n",
    "df_pension['Year'] = df_pension['Year'].astype(np.int64) # convert column year to integer\n",
    " \n",
    "# Merge dataframes above into one final dataframe\n",
    "df_final_1 = pd.merge(df_gdp, df_pop, on='Year')\n",
    "df_final_2 = pd.merge(df_final_1, df_labor, on='Year')\n",
    "df_final = pd.merge(df_final_2, df_pension, on='Year')\n",
    "\n",
    "\n",
    "# Re-calculate some figures to plot it accordingly\n",
    "df_final['LaborForce_mio'] = ((df_final['LaborForce'] / 1000) )\n",
    "df_final['Employed_mio'] = ((df_final['Employed'] / 1000) )\n",
    "df_final['65AndOlder_mio'] = ((df_final['Seniors > 65 yr'] / 1000000) )\n",
    "df_final['PensionCosts_bill'] = ((df_final['PensionCosts']  / 1000) )\n",
    "df_final['% Pension GNI'] = (df_final['PensionCosts'] / df_final['GrossNationalIncome'])*100\n",
    "df_final = df_final.set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Create charts below\n",
    "################################################################################\n",
    "# Create chart 1 - piechart\n",
    "def create_piecharts(pie_ax, data, year):\n",
    "    sizes = data.loc[year].values\n",
    "    pie_ax.set_title('Age group ={}'.format(year), horizontalalignment='center', verticalalignment='bottom', fontsize=8)\n",
    "    colors = ['yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "    patches, texts, autotexts = pie_ax.pie(sizes,  explode=(0, 0, 0.1), labels=data.columns.values, colors=colors,\n",
    "                                autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "    for i in range(3):\n",
    "            texts[i].set_fontsize(8)\n",
    "            autotexts[i].set_fontsize(8)   \n",
    "    return pie_ax\n",
    "    \n",
    "fig = plt.figure()\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2,\n",
    "                width_ratios=[1,1],\n",
    "                height_ratios=[1,1],\n",
    "                wspace=0.5, \n",
    "                hspace=0.5,\n",
    "                left=0.15)\n",
    "pie_age_gr_1975_ax = fig.add_subplot(gs[0,0])\n",
    "pie_age_gr_1988_ax = fig.add_subplot(gs[0,1])\n",
    "pie_age_gr_2000_ax = fig.add_subplot(gs[1,0])\n",
    "pie_age_gr_2013_ax = fig.add_subplot(gs[1,1])\n",
    "\n",
    "create_piecharts(pie_age_gr_1975_ax, df_pie_chart, 1975)\n",
    "create_piecharts(pie_age_gr_1988_ax, df_pie_chart, 1988)\n",
    "create_piecharts(pie_age_gr_2000_ax, df_pie_chart, 2000)\n",
    "create_piecharts(pie_age_gr_2013_ax, df_pie_chart, 2013)\n",
    "fig.suptitle('Evolution of age groups (seniors are highlighted)', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Create plot 2 - scatter diagram\n",
    "fig3 = sns.pairplot(df_final[['LaborForce_mio', 'PensionCosts_bill', '65AndOlder_mio']], diag_kind=\"kde\", markers=\"+\",\n",
    "                 plot_kws=dict(s=50, edgecolor=\"b\", linewidth=1),\n",
    "                 diag_kws=dict(shade=True), size=2.5);\n",
    "fig3.fig.subplots_adjust(top=0.9)\n",
    "fig3.fig.suptitle('Correlation between Pension Cost, Seniors (> 65 yr) and Labor Force', fontsize=11)\n",
    "\n",
    "xlabels,ylabels = [],[]\n",
    "new_labels = ['Labor force in mio', 'Pens. Costs bil. €', 'Seniors > 65 yr in mio']\n",
    "\n",
    "for ax in fig3.axes[-1,:]:\n",
    "    xlabel = ax.xaxis.get_label_text()\n",
    "    xlabels.append(xlabel)\n",
    "for ax in fig3.axes[:,0]:\n",
    "    ylabel = ax.yaxis.get_label_text()\n",
    "    ylabels.append(ylabel)\n",
    "\n",
    "    \n",
    "for i in range(len(xlabels)):\n",
    "    for j in range(len(ylabels)):\n",
    "        if j == 2:\n",
    "            fig3.axes[j,i].xaxis.set_label_text(new_labels[i], fontsize=8)\n",
    "        if i == 0:\n",
    "            fig3.axes[j,i].yaxis.set_label_text(new_labels[j], fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Create plot 3 - bar chart\n",
    "fig2 = plt.figure() # matplotlib figure\n",
    "ax = fig2.add_subplot(111)\n",
    "bar_width = 0.4\n",
    "opacity = 0.4\n",
    "\n",
    "rects1 = ax.bar(df_final.index.values, df_final['GrossNationalIncome'], bar_width,\n",
    "                alpha=opacity, color='b',\n",
    "                label='GNI')\n",
    "\n",
    "rects2 = ax.bar(df_final.index.values, df_final['PensionCosts'], bar_width,\n",
    "                alpha=opacity, color='#FFBE00',                \n",
    "                label='PensionCosts')\n",
    "\n",
    "# and the first axes using subplot populated with data \n",
    "ax.set_title('Absolute and relative comparison between gross national income (GNI) \\nand pension cost per year in billion €', y=1.08, fontsize=11)\n",
    "ax.set_xticks(df_final.index.values )\n",
    "ax.set_xticklabels(df_final.index.values)\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(0.025, 1.0, 1., .102), loc=3,  ncol=2)\n",
    "\n",
    "\n",
    "for rect in rects1:\n",
    "   \n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2.0, height*1.08, '%d' % int(height/1000), ha='center', va='center', fontsize=9, weight=\"bold\")\n",
    "\n",
    "for rect in rects2:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2.0, height*0.5, '%d' % int(height/1000), ha='center', va='center', fontsize=9, weight=\"bold\")    \n",
    "    \n",
    "#add second y-value at the right to present % increase of pension costs vs GNI\n",
    "ax2 = fig2.add_subplot(111, sharex=ax, frameon=False)\n",
    "line = ax2.plot(df_final['% Pension GNI'], 'or-')\n",
    "ax2.axes.get_yaxis().set_visible(False)\n",
    "ax2.legend(bbox_to_anchor=(0.025, 0.93, 1., .102), loc=3,  ncol=2)\n",
    "\n",
    "values = df_final['% Pension GNI'].values.copy()\n",
    "values = np.around(values.astype(np.double),2)\n",
    "maximum = np.amax(values) \n",
    "minimum = np.amin(values)\n",
    "diff = maximum - minimum\n",
    "for i, ln in enumerate(rects2):\n",
    "    barheight = 575000\n",
    "    height = ( ( (values[i] - minimum) / diff) + 0.09 ) * barheight \n",
    "    ax.text(ln.get_x() + ln.get_width()/2.0, height ,  '{} %'.format(values[i]) , ha='center', va='center', fontsize=9, weight=\"bold\")\n",
    "\n",
    "\n",
    "for item in [ax, ax2]:\n",
    "    item.patch.set_visible(False)\n",
    "    item.grid(False)\n",
    "\n",
    "    fig2.tight_layout() \n",
    "\n",
    "fig2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
